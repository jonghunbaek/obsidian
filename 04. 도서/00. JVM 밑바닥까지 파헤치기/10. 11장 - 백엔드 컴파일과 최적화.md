바이트 코드를 중간 단계로 볼 때, 네이티브 코드로 변환하는 과정은 전체 컴파일 과정 중 백엔드라고 볼 수 있다.
이러한 백엔드 역할을 하는 컴파일러가 바로 JIT컴파일러와 AOT 컴파일러다.

두 컴파일러 모두 JVM에서 필수 요소는 아니다.
→ JVM 명세 기준이므로 VM에 따라 지원 기능과 구현 방식이 완전히 다를 수 있음
하지만 두 컴파일러의 컴파일 성능과 품질은 **상용 VM의 우수성을 좌우하는 핵심 지표이기 때문에 사실상 필수**에 가깝다.

# 1. JIT 컴파일러
자주 실행 되는 메서드나 코드 블록을 핫스팟 코드 또는 핫 코드라고 부른다. 
이러한 핫스팟 코드를 런타임에 네이티브 코드로 컴파일하고 최적화를 수행하는 것이 바로 JIT 컴파일러다. 

## 1.1 인터프리터와 컴파일러
![[JVM 11장 - 인터프리터와 JIT 컴파일러의 관계.png|500]]
현 시대의 주류 상용 가상 머신은 대부분 인터프리터와 JIT 컴파일러를 함께 사용한다.

인터프리터의 주로 사용되는 경우는 다음과 같다.
- **컴파일 없이 프로그램을 빠르게 시작해야 할 때**
- **메모리가 부족한 환경에서 사용되어야 할 때**
- **JIT 컴파일러의 적극적 최적화가 실패할 때**
즉, 인터프리터는 JIT 컴파일러의 단점을 보완하는 역할을 한다.

### 계층형 컴파일 모드
핫스팟 가상 머신엔 2개 또는 3개의 JIT 컴파일러가 존재한다.
- **C1**(클라이언트 컴파일러)
- **C2**(서버 컴파일러)
- **그랄 컴파일러**
	- C2 대체 예정이었느나 JDK16부터 표준 JDK에선 배제되고, 그랄 VM의 프로젝트에서만 유지됨

기존의 핫스팟 VM의 인터프리터는 하나의 컴파일러와만 협력하여 작동했다.
하지만 현재는 호스트 모신의 하드웨어 성능과 자체 버전에 따라 실행 모드를 자동으로 선택한다.

JIT 컴파일러가 최적화를 수행하며 네이티브 코드로 컴파일하는 것은 시간이 오래 걸리는 작업이다.
또한 JIT 컴파일러가 더 많은 최적화를 수행하기 위해 인터프리터가 성능 모니터링 정보를 수집하는 것 역시 속도에 영향을 준다.
프로그램 시작 응답 속도와 운영 효율 사이의 균형을 찾기 위해 나온 것이 '계층형 컴파일' 기능이다. 

![[JVM 11장 - 계층형 컴파일.png]]
계층형 컴파일은 다음과 같은 단계로 수행된다.
- **계층 0**
	- 인터프리터가 바이트 코드를 해석하며, 성능 모니터링을 수행하지 않음
- **계층 1**
	- 클라이언트 컴파일러가 사용되며, 간단하고 안정적인 최적화를 수행. 성능 모니터링은 수행하지 않음
- **계층 2**
	- 클라이언트 컴파일러가 사용되며, 몇 가지 성능 모니터링을 수행함
- **계층 3**
	- 클라이언트 컴파일러가 사용되며, 모든 종류의 성능 모니터링이 수행됨
- **계층 4**
	- 서버 컴파일러가 사용되며, 성능 모니터링 정보를 활용해 시간이 오래 걸리는 최적화도 수행. 신뢰도가 낮은 공격적인 최적화를 수행하기도 함

계층형 컴파일이 도입된 뒤로는 인터프리터, C1, C2 컴파일러가 협력하며 동작하고 핫 코드가 여러 번 컴파일될 수 있다.
→ 해석 속도는 인터프리터 > C1 > C2 순이다.

### 1. 2 컴파일 대상과 촉발 조건
핫 코드의 대표적인 유형은 다음과 같다.
- **여러 번 호출되는 메서드**
- **여러 번 실행되는 순환문의 본문**
	- 실제 메서드의 호출 횟수가 적어도 핫 코드가 될 수 있음

두 유형 모두 메서드 전체를 타겟으로 한다. 
두 번째 유형에선 순환문이 작동하는 시점에 최적화가 수행될 수 있다.
이 때,  메**서드의 실행 진입점(루프의 시작 지점?)이 살짝 달라지며, 컴파일 시 진입점의 바이트코드 인덱스 값을 컴파일러에 전달**한다. 
메서드의 스택 프레임이 스택에 존재하는 상태에서 치환되기 때문에 **온스택 치환**(OSR)이라고 한다.

### 여러 번이라는 표현은 주관적
JIT 컴파일러가 촉발되는 조건을 판단하는 것을 핫스팟 코드 탐지 또는 핫스팟 탐지라고 하며 다음과 같은 방식으로 수행될 수 있다.
- **샘플 기반 핫스팟 코드 탐지**
	- 각 스레드 호출 스택 상단을 샘플링하여 자주 발견되는 메서드를 핫 메서드로 간주
	- 정확도가 떨어지며, 스레드 블로킹 등 외부 요인이 핫스팟 탐지를 방해
- **카운터 기반 핫스팟 코드 탐지**
	- 각 메서드와 코드 블록에 대한 카운터를 설정하여 개별 실행 횟수를 기록
	- 실행 횟수가 문턱값을 초과하면 핫 메서드로 간주
	- 구현이 어렵지만 더 정확한 결과를 얻을 수 있음
두 방식 모두 상용 가상 머신에서 사용되며, 핫스팟 VM에선 카운터 방식이 사용된다.
핫스팟 VM에선 메서드 각각에 대해 **메서드 호출 카운터와 백 에지 카운터를 준비하고 이를 토대로 JIT 컴파일 촉발 조건을 판별**한다.

아래 두 방식은 클라이언트 모드의 JIT 컴파일 방식만을 보여준다. 서버 모드는 더 복잡하게 구현되어 있다.
### 메서드 호출 카운터에 의한 JIT 컴파일 촉발
#### 메서드 호출 카운터의 작동 방식
메서드가 호출되면 VM은 해당 메서드의 JIT 컴파일 버전의 존재 여부를 확인한다. 
있다면 컴파일된 네이티브 코드를 실행하고, 
없다면 카운터의 값을 1 증가 시킨 후에 메서드 호출 카운터와 백 에지 카운터 값의 합이 문턱 값을 넘어서면 컴파일을 요청한다.

이 때, 따로 설정하지 않았다면 **VM 실행 엔진은 컴파일이 완료될 때까지 인터프리터로 작업을 계속**한다.
즉, **JIT 컴파일 작업은 백그라운드에서 비동기로 수행**된다.
컴파일 완료 후엔 메서드의 호출 진입점 주소가 시스템에 의해 자동으로 새 값으로 덮어 써지고, 그 다음 호출부터는 컴파일된 버전이 사용된다. 
#### 메서드 호출 카운터의 카운팅 단위 시간
메서드 호출 카운터는 '단위 시간당 호출 횟수'를 계산한다.
만약 **단위 시간 동안 집계 횟수가 문턱 값을 넘어서지 못한다면 카운터의 값을 반으로 줄이게** 된다. 
이 방식을 '카운트 감쇠 메서드 호출(counter decay method invocation)'이라고 한다. 

### 백 에지 카운터에 의한 JIT 컴파일 촉발
#### 백 에지 카운터 작동 방식
백 에지는 순환문 경계에서 순환문 처음으로 점프한다는 뜻이다.
그러므로 백 에지 카운터란 순환문의 반복 횟수라고 볼 수 있다.
이 카운터를 사용하는 목적은 OSR을 촉발하기 위함이다.

인터프리터는 **백 에지 명령어를 만나면 실행할 코드 조각의 컴파일된 버전이 있는지 먼저 확인**한다.
있다면, 컴파일된 네이티브 코드를 실행하고,
없다면 백 에지 카운터의 값을 1 증가 시킨다. 
이후 **메서드 호출 카운터와 백 에지 카운터의 합이 문턱 값을 넘기면 OSR 컴파일을 요청**한다. 
이 때, 백 에지 카운터의 값을 약간 줄이는데, 컴파일러가 컴파일을 마칠 때까지 인터프리터에서 순환문을 계속 실행하기 위해서다. 

메서드 호출 카운터와 달리 **감쇠 없이 절대 실행 횟수를 계산**한다.

## 3. 컴파일 과정
### 클라이언트 컴파일러의 컴파일 과정
![[JVM 11장 - 클라이언트 컴파일러 아키텍처.png|500]]
- **단계 1**
	- 플랫폼 독립적 프론트엔드가 타겟 독립적 중간 표현인 HIR을 생성
	- HIR은 코드 값을 SSA로 표현해줘 몇 가지 최적화가 더 쉽도록 도와줌
	- 더불어 HIR로 변환하기 전에 메서드 인라인, 상수 전파 등의 기본적인 최적화를 수행
- **단계 2**
	- 플랫폼 의존적 백엔드가 HIR로부터 LIR을 생성
	- LIR 변환 전에 HIR을 대상으로 null 검사 제거, 범위 검사 제거 등의 최적화를 수행하여 HIR이 코드를 더 효율적으로 표현하도록 최적화
- **단계 3**
	- 플랫폼 의존적 백엔드가 선형 스캔 레지스터 할당(linear scan register allocation)을 사용해 LIR에 레지스터를 할당하고 핍홀 최적화를 수행한 다음 네이티브 코드 생성

>[!NOTE]
>**HIR? LIR?**
>두 개념은 바이트코드를 네이티브 코드로 컴파일 하는 과정에서 컴파일 과정을 쉽게 하도록 도와주는 중간 단계의 언어 역할을 함
>HIR → High-level Intermediate Representation
>LIR → Low-level Intermediate Representation

>[!NOTE]
>**정적 단일 할당(SSA(Static Single Assignment))이란?**
>모든 변수에 단 한 번만 값을 할당하는 형태로 프로그램을 변환하는 것
>int a = 1;
>a = a + 2;
>위와 같은 원본 코드가 컴파일 과정을 거쳐
>int a1 = 1;
>int a2 = a1 + 2;
>와 같은 형태가 되는 과정으로 볼 수 있다.

>[!NOTE]
>**핍홀 최적화란?**
>아주 짧은 코드 조각을 보고 불필요한 명령어를 최적화 하는 작업
>책으로 치면 책 전체가 아니 아주 작은 일부분의 문장만 다듬는 것

### 서버 컴파일러의 컴파일 과정
서버 컴파일러는 서버용 애플리케이션들의 일반적인 시나리오를 감안하여 서버 측 성능을 극대화하도록 설정된 컴파일러다.
대부분의 성능 최적화를 수행하며, 안정성이 다소 떨어지는 예측 최적화도 수행한다.

서버 컴파일러가 사용한느 레지스터 할당기는 RISC 같은 일부 프로세서 아키텍처의 커다란 레지스터 집합의 이점을 활용할 수 있는 전역 그래프 셰이더 할당기다.

표준 JIT 컴파일에서 서버 컴파일러는 상대적으로 느리지만 전통적인 정적 최적화 컴파일러보단 훨씬 빠르다. 
또한 생성된 네이티브 코드의 성능이 클라이언트 컴파일러의 결과물보다 압도적으로 좋아 시간이 오래 걸린다는 단점 대부분이 상쇄된다.

# 4. AOT 컴파일러
초창기에 잠시 사용되다 자바의 이념과 맞지 않아 오랜 시간 잊혀졌던 컴파일러다. 
하지만 2013년 안드로이드의 AOT 컴파일을 중심으로 한 ART 등장으로 상황은 뒤바뀌었다. 

## 4.1 AOT 컴파일러 특징
AOT 컴파일 관련 연구는 크게 두 가지로 나뉜다. 
- **프로그램 실행 전, 프로그램 코드를 네이티브 코드로 컴파일**
- **JIT 컴파일러가 런타임에 수행해야 하는 작업을 미리 수행해 캐시에 저장**

첫 번째는 AOT 컴파일러의 장점이자, JIT 컴파일러의 단점이다.
JIT 컴파일러는 런타임에 애플리케이션이 사용할 수 있는 컴퓨팅 리소스를 사용하기 때문이다. 

두 번째의 핵심은 JIT 컴파일러의 캐시 역할을 극대화하여 자바 프로그램 구동 시간을 단축하고, 구동 후 빠르게 최상의 성능을 내는 것이다. 
현재 주류 상용 JDK는 이 방식의 고급 컴파일을 모두 지원한다. 

### JIT 컴파일러가 AOT 컴파일러보다 나은 점
- **성능 모니터링 기반 최적화**
	- 런타임에 수집하므로 더 정확한 데이터를 수집할 수 있음
- **급진적 예측 최적화**
	- 예측이 실패해도 인터프리터라는 탈출 비상구가 존재함
	- AOT는 프로그램 실행 전에 완성되기에 '하지만 빨랐죠'와 같은 실패가 허용되지 않음
- **링크 타임 최적화**
	- C/C++과 같은 프로그램에선 메인 프로그램의 코드와 동적 링크 라이브러리는 완전히 독립적으로 컴파일되며 자신만을 고려해 컴파일 됨
	- 자바는 런타임에 동적으로 링크되기에 최적화가 쉬움
# 5. 컴파일러 최적화 기법
컴파일러의 목표는 단순히 소스 코드를 목적 코드로 변환하는 것이 아니다.
**출력된 코드가 얼마나 잘 최적화가 되어 있냐가 더 중요한 목표**다.

## 5.1 메서드 인라인
메서드 인라인은 소스 코드와 마찬가지로 컴파일 과정에서도 매우 중요한 기초적인 최적화다.
→ 소스 코드 레벨에서도 메서드 인라인은 리팩터링을 통한 가독성 향상에 기여하는 기초적인 최적화다.

메서드 인라인은 기본적으로 메서드 호출 비용을 줄여준다. 
```java
public static void foo(Object obj) {
	if (obj != null) {
		System.out.println("do something");
	}
}

public static void testInline(String[] args) {
	Object obj = null;
	foo(obj);
}
```
위 코드에서 testInline()메서드 내부는 모두 죽은 코드다. 
즉, 실제로 실행될 일이 없는 코드다. 
이런 경우 메서드 인라인을 하는데 하지 않는다면 죽은 코드 최적화를 시도해도 이 코드의 존재를 알 수 없다. 

메서드 인라인의 동작 원리는 어렵지 않지만 실제로 구현하기 위해 일어나는 일은 훨씬 복잡하다. 
특히 **JVM에서 일어나는 메서드 인라인은 고전적인 컴파일 최적화 이론에선 불가능한 일**이다.

### 메서드 인라인이 불가능한 이유?
8장에서 배웠듯 private, static 메서드와 같은 일부 메서드를 제외하곤 자바의 기본 인스턴스 메서드는 가상 메서드다. 
**가상 메서드는 런타임에 메서드 수신자를 선택해야 하는데 이 때문에 메서드 인라인이 불가능하다고 말하는 것**이다.

JVM에선 이를 해결하기 위해 클래스 계층 분석 기술을 도입했다. 
비가상 메서드는 바로 인라인할 수 있고 안전하다. 
만약 메서드 수신자가 될 수 있는 후보가 여러 개라면 다음과 같은 방식들을 사용한다.
- **후보가 1개만 존재**(가이디드 인라인)
	- 애플리케이션이 지금 모습에서 변하지 않을 것이라고 가정(**급진적 예측 최적화**)
	- 틀릴 경우 인터프리터를 사용
- **후보가 여러 개일 경우**
	- 인라인 캐시를 활용. 메서드를 실제로 호출하지만 가상 메서드 테이블을 확인하는 방식보다는 빠름
		- 첫 번째 호출 이후 메서드 수신자의 버전 정보가 캐시에 기록됨
		- 이후에도 호출되는 버전이 같다면 모노모픽 인라인 캐시라고 함
		- 만약 달라진다면 다형성을 이용한다는 뜻이며, 메가모픽 인라인 캐시라고 함
		- 이 경우 가상 메서드 테이블 방식과 똑같은 부하를 발생시킴
결과적으로 **JVM이 수행하는 메서드 인라인은 대부분 급진적 최적화**다.
그리고 이 방식이 가능한 이유는 인터프리터라는 퇴로가 존재하기 때문이다.

## 5.2 탈출 분석
탈출 분석은 새로 만들 객체가 사용되는 범위를 분석하여 자바 힙 할당 여부를 결정하는 기술이다.
메서드 인라인과 마찬가지로 다른 최적화를 위해 기초를 닦는 분석 기법이다.

탈출 분석에선 객체의 동적 범위를 분석하여 탈출 수준을 다음과 같이 구분한다.
- **전역 탈출**
- **인수 탈출**
- **탈출하지 않음**